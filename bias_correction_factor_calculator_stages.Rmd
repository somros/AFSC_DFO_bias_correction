---
title: "Calculation of bias corrrection factor for AFSC and DFO bottom trawl data - by stage"
author: "Alberto Rovellini"
date: "11/29/2021"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This document reads AFSC and DFO bottom trawl data, and reads/calculates CPUE for all Atlantis functional groups. It then subsets to
data points in the SE GOA and N BC, between 54 and 55 N. The two surveys meet approximately at 54.5N. It then calculates average CPUE per species over the 2005-2019 period. The goal is to identify consistent between-survey bias in the catchability of some species. Once such bias (i.e. difference in mean CPUE) is identified, we can apply it to correct the DFO data. The correction has the shape CPUE_AKFIN/CPUE_DFO, and it will be applied to the DFO CPUE per Atlantis box, rather than to the raw data. Think of reasons why this is not a good idea. We correct the DFO data no matter where the skew is because we have DFO data for fewer years and smaller area than GOA data.

Some observations:

1. An attempt was made to characterize bias by year. This was dropped because the sample size for the AFSC is too small in the area of interest.
2. In general, sample size is different, i.e. there are a lot more tows for the DFO sets than for AFSC.
3. Initially I excluded the WCHG data, since we do not use those for sdmTMB. However, that data contains shelf and slope information for the BC part of the model. Hecate Strait is a relatively shallow flat (mud? sand? rock?), and as such likely a different habitat from the GOA shelf. For this reason, WCHG is actually useful to have here. Since we are not considering years for the purposes of this, it does not matter that that is the only area sampled in even years.
4. A proper depth structure is difficult to achieve. FOr example, one would like to have bias specific to depth bins. However, AFSC data points are not enough for this. For this reason, we use 200 m as arbitrary cutoff between "shallow" and "deep" areas, to keep at least some depth structure in the bias correction.
5. Points 1 and 4 mean that we assume that: (a) the bias does not change over time; (b) the bias may change at different depths. Get back to this after reading about differences in the gear setup (e.g. height above bottom). Fishing protocol is similar (3 knots, ~15 minutes tows, skipper decides whether a place can be towed or not, etc.). So what could cause a bias then? Is there a reason to believe that differences are due to sampling bias and not to differences in habitat?
6. Here we are using data from all months for both AKFIN and DFO. Because we had to get rid of the temporal structure, there may be bias deriving from a sampling bias between different months. I am assuming that, because most sampling events are in the summer months for both data sets, any potential outlier coming from sampling in September or October (very few instances in the AFSC data) should be evened out over the time period we are considering.

```{r}
library(tidyverse)
library(data.table)
library(sf)
library(maps)
library(mapdata)
library(viridis)
```

```{r}
select <- dplyr::select
```

Read data. AFSC CPUE is calculated in another script (follow path) from AKFIN's [RACE catch data](.psmfc.org/akfin-answers/). DFO CPUE is obtained from DFO's [Groundfish Synoptic Bottom Trawl Surveys](https://open.canada.ca/data/en/dataset/a278d1af-d567-4964-a109-ae1e84cbd24a). 

AKFIN data was already converted from catch to CPUE, DFO data needs to be converted here.
```{r}
# AFSC CPUE
load("C:/Users/Alberto Rovellini/Documents/GOA/SDM/sdmTMB_stages/catch_to_CPUE_AKFIN/cpue_by_stage.Rdata")
akfin_data <- cpue
rm(cpue)

# DFO CPUE
load("C:/Users/Alberto Rovellini/Documents/GOA/SDM/Canada_stages/catch_to_CPUE_DFO/cpue_by_stage_DFO.Rdata")
dfo_data <- catch_all_hauls
dfo_data <- dfo_data %>% select(-survey) %>% set_names(names(akfin_data))
rm(catch_all_hauls)

# akfin hauls
akfin_hauls <- read.csv("C:/Users/Alberto Rovellini/Documents/GOA/SDM/sdmTMB_stages/catch_to_CPUE_AKFIN/Haul Descriptions.csv", fileEncoding = "UTF-8-BOM")

# dfo hauls
load('C:/Users/Alberto Rovellini/Documents/GOA/SDM/Canada_stages/catch_to_CPUE_DFO/hauls_dfo.Rdata')
dfo_hauls <- effort_all
rm(effort_all)
```

Add one column with name and stage.
```{r}
akfin_data <- akfin_data %>% mutate(Name_stage = paste0(CN,STAGE))
dfo_data <- dfo_data %>% mutate(Name_stage = paste0(CN,STAGE))
```

Let's write a function that:

* Gets the data for each functional group.
* Adds zero-catches to both AKFIN and DFO data.
* Subsets the data sets to the latitude of interest (54-55).
* Assigns a survey factor.
* Calculates the mean CPUE by depth strata (200 m breakpoint).
* Calclates the bias correction factor.
* Plots the biomass values and saves the plot.

```{r}
get_bias_correction <- function(this_group_stage){
  
  # subset to this group and stage
  akfin_data <- akfin_data %>% filter(Name_stage==this_group_stage)
  dfo_data <- dfo_data %>% filter(Name_stage==this_group_stage)
  
  # add empty hauls to akfin data
  data_hauls <- levels(factor(akfin_data$HAULJOIN))
  zero_hauls <- setdiff(levels(factor(akfin_hauls$Haul.Join.ID)), data_hauls) # assuming that if there are no records from a haul, the catch in that haul was 0 for this species
  
  # make a data frame to bind by row
  zero_catches <- akfin_hauls %>% filter(Haul.Join.ID %in% zero_hauls) %>% 
    select(Year, Haul.Join.ID, Ending.Latitude..dd., Ending.Longitude..dd., Bottom.Depth..m.) %>% 
    mutate(species_code = rep(NA, length(Year)),
           name = rep(NA, length(Year)),
           stage = rep(NA, length(Year)),
           biom_kgkm2 = rep(0, length(Year)),
           Name_stage = rep(this_group_stage, length(Year))) %>%
    set_names(names(akfin_data))
  
  # attach by row to race_data
  akfin_data <- rbind(akfin_data, zero_catches)
  # ditch hauls with empty lat or lon
  akfin_data <- akfin_data %>% filter(!is.na(LAT) | !is.na(LON))
  # and with NA depths
  akfin_data <- akfin_data %>% filter(!is.na(DEPTHR))
  
  # dfo data
  data_hauls <- levels(factor(dfo_data$HAULJOIN))
  zero_hauls <- setdiff(levels(factor(dfo_hauls$Haul.Join.ID)), data_hauls) # assuming that if there are no records from a haul, the catch in that haul was 0 for this species
  
  # make a data frame to bind by row
  zero_catches <- dfo_hauls %>% filter(Haul.Join.ID %in% zero_hauls) %>% 
    select(Survey.Year, Haul.Join.ID, End.latitude, End.longitude, Bottom.depth..m.) %>% 
    mutate(species_code = rep(NA, length(Survey.Year)),
           name = rep(NA, length(Survey.Year)),
           stage = rep(NA, length(Survey.Year)),
           biom_kgkm2 = rep(0, length(Survey.Year)),
           Name_stage = rep(this_group_stage, length(Survey.Year))) %>%
    set_names(names(dfo_data))
  
  # attach by row to dfo_data
  dfo_data <- rbind(dfo_data, zero_catches)
  # ditch hauls with empty lat or lon
  dfo_data <- dfo_data %>% filter(!is.na(LAT) | !is.na(LON))
  # and with NA depths
  dfo_data <- dfo_data %>% filter(!is.na(DEPTHR))
  
  # subset to same years
  #years <- intersect(akfin_data %>% select(year) %>% distinct() %>% pull(), dfo_data %>% select(year) %>% distinct() %>% pull())
  years <- seq(2005,2019,1) # just capture everything since the inception of the DFO surveys (except 2003, because they did not sample up there)
  
  akfin_data <- akfin_data %>% filter(YEAR %in% years)
  dfo_data <- dfo_data %>% filter(YEAR %in% years)
  
  # add survey factor
  akfin_data <- akfin_data %>% mutate(SURVEY = "AFSC")
  dfo_data <- dfo_data %>% mutate(SURVEY = "DFO")
  
  # stitch them
  all_data <- rbind(akfin_data, dfo_data) # CAUTION: assuming that the projection is the same - go check
  all_data <- all_data %>% filter(LAT>=54 & LAT <= 55 & LON > -135)
  # all_data <- all_data %>% filter(year != 2003)
  
  # add depth factor, either as depth bins or as shallow/deep
  max_depth <- max(all_data$DEPTHR)
  #all_data <- all_data %>% mutate(depth_bin = cut(all_data$depth, breaks = seq(0,max(all_data$depth),100), labels = seq(100,max(all_data$depth),100)))
  #all_data <- all_data %>% mutate(depth_bin = ifelse(all_data$depth<max_depth/2,"Shallow","Deep"))
  # alternative for data including WCHG, which is very deep. Use break at 200 m instead (one of our Atlantis breaks)
  all_data <- all_data %>% mutate(DEPTH_BIN = ifelse(all_data$DEPTHR<200,"Shallow (<200m)","Deep (>200m)"))
  
  mean_cpues <- all_data %>% group_by(SURVEY,DEPTH_BIN) %>%# group_by(survey,year,depth_bin) %>%
    summarise(MEAN_CPUE = mean(BIOM_KGKM2), SE_CPUE = sd(BIOM_KGKM2)/sqrt(length(BIOM_KGKM2)), DATA_POINTS = length(BIOM_KGKM2))
  
  p <- ggplot(mean_cpues)+
    geom_bar(aes(x = SURVEY, y = MEAN_CPUE, fill = SURVEY), position = "dodge", stat = "identity")+
    geom_errorbar(aes(x = SURVEY, y = MEAN_CPUE, ymin = MEAN_CPUE, ymax = MEAN_CPUE+SE_CPUE), 
                  position = "dodge", stat = "identity")+
    geom_text(aes(x = SURVEY, y = MEAN_CPUE-(MEAN_CPUE*0.15), label = DATA_POINTS), 
              position = "dodge", size = 3)+
    theme_bw()+
    labs(title = this_group_stage)+
    facet_wrap(~DEPTH_BIN)
  p
  
  # calculate correction factor as AKFIN/DFO and use it as scalar for DFO biomass estimates by box
  
  correction_shallow <- mean_cpues %>% filter(DEPTH_BIN == "Shallow (<200m)" & SURVEY == "AFSC") %>% select(MEAN_CPUE) %>% pull()/
    mean_cpues %>% filter(DEPTH_BIN == "Shallow (<200m)" & SURVEY == "DFO") %>% select(MEAN_CPUE) %>% pull()
  
  correction_deep <- mean_cpues %>% filter(DEPTH_BIN == "Deep (>200m)" & SURVEY == "AFSC") %>% select(MEAN_CPUE) %>% pull()/
    mean_cpues %>% filter(DEPTH_BIN == "Deep (>200m)" & SURVEY == "DFO") %>% select(MEAN_CPUE) %>% pull()
  
  corrs <- data.frame("group" = this_group_stage, "shallow" = correction_shallow, "deep" = correction_deep)
  
  ggsave(paste("C:/Users/Alberto Rovellini/Documents/GOA/SDM/Bias_correction/bias_images_stages/", this_group_stage, ".png", sep = ""), p, width = 4.2, height = 3, dpi = 300, units = "in")
  
  return(corrs)
}
```

Apply the function above to all groups that appear in both data sets.
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# identify the groups in common
groups_akfin <- akfin_data %>% select(Name_stage) %>% distinct() %>% pull()
groups_dfo <- dfo_data %>% select(Name_stage) %>% distinct() %>% pull()

ag <- intersect(groups_akfin,groups_dfo) # these will be the groups in common

bias_corrections <- lapply(ag,get_bias_correction)

corr_factors <- rbindlist(bias_corrections)

write.csv(corr_factors,"correction_factors_stages.csv",row.names = FALSE) # CPUE values in boxes >91 to be multiplied by these factors
```